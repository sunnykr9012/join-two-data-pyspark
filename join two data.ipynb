{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b455eec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
      "     -------------------------------------- 281.4/281.4 MB 2.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting py4j==0.10.9.5\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "     -------------------------------------- 199.7/199.7 kB 6.1 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py): started\n",
      "  Building wheel for pyspark (setup.py): still running...\n",
      "  Building wheel for pyspark (setup.py): finished with status 'done'\n",
      "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824023 sha256=bd06028ef32e46a104cb7e87e836a4058f7dc40b5c00ba00c0c809033daf6431\n",
      "  Stored in directory: c:\\users\\pc\\appdata\\local\\pip\\cache\\wheels\\6c\\e3\\9b\\0525ce8a69478916513509d43693511463c6468db0de237c86\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "996ab8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=(SparkSession\n",
    ".builder\n",
    ".appName(\"sunny\")\n",
    ".getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10e7c58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "115814b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=spark.sparkContext\n",
    "sqlContext=spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46a7b966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'git' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/jonesberg/DataAnalysisWithPythonAndPySpark-Data.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f68483a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Path does not exist: file:/content/DataAnalysisWithPythonAndPySpark-Data/gutenberg_books/1342-0.txt",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11468\\3309090934.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/content/DataAnalysisWithPythonAndPySpark-Data/gutenberg_books/1342-0.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36mtext\u001b[1;34m(self, paths, wholetext, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[0mpaths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m     def csv(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    194\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: Path does not exist: file:/content/DataAnalysisWithPythonAndPySpark-Data/gutenberg_books/1342-0.txt"
     ]
    }
   ],
   "source": [
    "book=spark.read.text(\"/content/DataAnalysisWithPythonAndPySpark-Data/gutenberg_books/1342-0.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ecad7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f639b7ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Path does not exist: file:/content/DataAnalysisWithPythonAndPySpark-Data/broadcast_logs/BroadcastLogs_2018_Q3_M8_sample.CSV",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11468\\402881286.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mDIRECTORY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"/content/DataAnalysisWithPythonAndPySpark-Data/broadcast_logs\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m logs=spark.read.csv(\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDIRECTORY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"/content/DataAnalysisWithPythonAndPySpark-Data/broadcast_logs/BroadcastLogs_2018_Q3_M8_sample.CSV\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"|\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[1;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 535\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    194\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: Path does not exist: file:/content/DataAnalysisWithPythonAndPySpark-Data/broadcast_logs/BroadcastLogs_2018_Q3_M8_sample.CSV"
     ]
    }
   ],
   "source": [
    "DIRECTORY=\"/content/DataAnalysisWithPythonAndPySpark-Data/broadcast_logs\"\n",
    "logs=spark.read.csv(\n",
    "os.path.join(DIRECTORY,\"/content/DataAnalysisWithPythonAndPySpark-Data/broadcast_logs/BroadcastLogs_2018_Q3_M8_sample.CSV\"),\n",
    "sep=\"|\",\n",
    "header=True,\n",
    "inferSchema=True,\n",
    "timestampFormat=\"yyyy-MM-dd\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fae4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs=spark.read.csv(\n",
    "os.path.join(DIRECTORY,\"/content/DataAnalysisWithPythonAndPySpark-Data/broadcast_logs/BroadcastLogs_2018_Q3_M8_sample.CSV\"),\n",
    "sep=\"|\",\n",
    "header=True,\n",
    "inferSchema=True,\n",
    "timestampFormat=\"yyyy-MM-dd\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f620cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54af3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs.toPandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4decc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree format show\n",
    "logs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b866ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs.select(\"BroadcastLogID\",\"LogServiceID\",\"Language2\",\"DubDramaCreditID\",\"LogDate\").show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06398cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs.select(\"BroadcastLogID\",\"LogServiceID\",\"LogDate\")\n",
    "logs.select(*[\"BroadcastLogID\",\"LogServiceID\",\"LogDate\"])\n",
    "logs.select(\n",
    "     f.col(\"BroadCastLogID\"),f.col(\"LogServiceID\"),f.col(\"LogDate\")\n",
    ")\n",
    "logs.select(\n",
    "    *[f.col(\"BroadCastLogID\"),f.col(\"LogServiceID\"),f.col(\"LogDate\")]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb827b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1038a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_split=np.array_split(np.array(logs.columns),len(logs.columns)// 3)\n",
    "print(column_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573765d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in logs.columns:\n",
    "  logs.select(i).summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba1ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in column_split:\n",
    "  logs.select(*x).show(5,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec87dbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_src=DIRECTORY\n",
    "wholeRDD=sc.wholeTextFiles(DIRECTORY)\n",
    "wholeRDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6ec058",
   "metadata": {},
   "outputs": [],
   "source": [
    "myRDD=sc.parallelize([1,2,3,4,5,6])\n",
    "print(\"this RDD has\", myRDD.count(),\"element\")\n",
    "print(\"the first element is\", myRDD.first())\n",
    "print(\"the first 2 element are\", myRDD.take(2))\n",
    "print(\"the entire collection is\",myRDD.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6641a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "myRDD=sc.parallelize([1,2,3,4,5,6])\n",
    "myRDD.saveAsTextFile(\"myFirstRDD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ecd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "myRDD=sc.parallelize([1,2,3,4,5,6])\n",
    "myRDDsum=myRDD.reduce(lambda l, r: l+r)\n",
    "print(\"The sum of my RDD is\", myRDDsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a9c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wow_print(e):\n",
    "  print(\"-\"*(len(e)+4))\n",
    "  print(\"*\",e,\"*\")\n",
    "  print(\"-\"*(len(e)+4))\n",
    "my_fruits=[\"apples\",\"oranges\",\"pear\",\n",
    "\"banana\"]\n",
    "dataRDD = sc.parallelize(my_fruits)\n",
    "print(\"The output of foreach is:\", \n",
    "dataRDD.foreach(wow_print))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a53bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_fruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33fce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs.select(\n",
    "    f.col(\"Duration\"),\n",
    "    (\n",
    "        f.col(\"Duration\").substr(1,2).cast(\"int\")*60 *60\n",
    "     +f.col(\"Duration\").substr(4,2).cast(\"int\")*60 \n",
    "     +f.col(\"Duration\").substr(7,2,).cast(\"int\")\n",
    "    ).alias(\"Duration_second\"),\n",
    ").distinct().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28129db",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs=logs.withColumn(\n",
    "    \"Duration_seconds\",\n",
    "    (\n",
    "      f.col(\"Duration\").substr(1,2).cast(\"int\")*60 *60\n",
    "     +f.col(\"Duration\").substr(4,2).cast(\"int\")*60 \n",
    "     +f.col(\"Duration\").substr(7,2,).cast(\"int\")\n",
    "    ),\n",
    ")\n",
    "logs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f2ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs.toDF(*[x.lower() for x in logs.columns]).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f530dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs.select(sorted(logs.columns)).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1769f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in logs.columns:\n",
    "  logs.describe(i).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c2eea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatRDD=dataRDD\\\n",
    "  .flatMap(lambda line: line.split(' ')).union(dataRDD)\n",
    "for line in flatRDD.collect():\n",
    "  print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cb1adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_fruits=[\"apple oranges pear\", \"banana apple\"]\n",
    "dataRDD=sc.parallelize(my_fruits)\n",
    "print(\"number of element is the RDD:\", dataRDD.count())\n",
    "print(\"it contains the following string:\", dataRDD.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762844ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits1=[\"apple\",\"orange\",\"pera\"]\n",
    "fruits2=[\"banana\",\"orange\",\"apple\"]\n",
    "fruits1RDD=sc.parallelize(fruits1)\n",
    "fruits2RDD=sc.parallelize(fruits2)\n",
    "\n",
    "fruits1RDD.union(fruits2RDD).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c15758",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits1RDD.subtract(fruits2RDD).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e6975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits1RDD.cartesian(fruits2RDD).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9199b6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits1RDD.subtract(fruits2RDD).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a08bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "myRDD=sc.parallelize(range(100))\n",
    "print(myRDD.sample(False,0.3).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28fec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "myRDD=sc.parallelize(range(100))\n",
    "print(myRDD.sample(True,0.3,123).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_src=[\"having\",\"fun\",\"learning\",\"spark\"]\n",
    "script_path=\"/home/student/Data/repeat.sh\"\n",
    "myRDD=sc.parallelize(data_src)\n",
    "pipeRDD=myRDD.pipe(script_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9de142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_fruits=[\"apples\",\"oranges\",\"pear\",\"banana\"]\n",
    "pairRDD=sc.parallelize(my_fruits)\\\n",
    "          .keyBy(lambda fruit: len(fruit))\n",
    "for i in pairRDD.collect():\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193ef5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_fruits=[(\"henry\",\"apples grapes banana\"),\n",
    "            (\"shaun\",\"watermelon strawberry\"),\n",
    "            (\"sharon\",\"pear apples kiwi\",)\n",
    "]\n",
    "pairRDD=sc.parallelize(fav_fruits)\\\n",
    "          .flatMapValues(lambda fruits: fruits.split(\" \"))\n",
    "for i in pairRDD.collect():\n",
    "  print(i)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbef99e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
